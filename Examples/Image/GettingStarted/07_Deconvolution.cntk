# Parameters can be overwritten on the command line
# for example: cntk configFile=myConfigFile RootDir=../.. 
# For running from Visual Studio add
# currentDirectory=$(SolutionDir)/<path to corresponding data folder> 

command = trainNetwork:testNetwork:writeResults
#command = writeResults

precision = "float"; traceLevel = 1 ; deviceId = "auto"

rootDir = ".." ; dataDir = "$rootDir$/DataSets/MNIST" ;
outputDir = "./Output" ;

modelPath = "$outputDir$/Models/07_Deconvolution.model"
#stderr = "$outputDir$/07_Deconvolution_bs_out"

# TRAINING CONFIG
trainNetwork = {
    action = "train"
    
    BrainScriptNetworkBuilder = {
        model = inputFeatures => {
            c1      = ConvolutionalLayer {16, (5:5), pad = true}(inputFeatures)
            r1      = ReLU(c1)
            p1      = MaxPoolingLayer {(2:2), stride=(2:2)}(r1)
            unpool1 = MaxUnpooling(p1, r1, (2:2:1), stride=(2:2:1), autoPadding=(false:false:false), lowerPad=0, upperPad=0)
            W       = ParameterTensor{(1:5:5:16), init="uniform", initValueScale=0.1, initOnCPUOnly=true}
            deconv  = Convolution(W, unpool1, (5:5:1), mapDims=16, stride=(1:1), sharing=(true:true:true), autoPadding=(false:false:false), lowerPad=(2:2:0), upperPad=(2:2:0), deconv=true)
        }.deconv

        # inputs
        imageShape = 28:28:1                        # image dimensions, 1 channel only
        features = Input {imageShape}
        labelDim = 10
        labels = Input (labelDim)

        featScale = 1/256
        Scale{f} = x => Constant(f) .* x

        #Scale = x => (1.0 / 256.0) .* x
        #featScaled = Scale (features)
        
        # apply model to features
        f1 = Scale{featScale} (features)
        z = model (f1)

        # rmse loss function
        f2 = Scale{featScale} (features)
        err = z - f2 #featScaled
        sqErr = err .* err
        mse = ReduceMean(sqErr)
        rmse = Sqrt(mse)
        
        # declare special nodes
        featureNodes = (features)
        labelNodes = (labels)
        criterionNodes = (rmse)
        evaluationNodes = (rmse)
        outputNodes = (z)
    }

    SGD = {
        epochSize = 60000
        minibatchSize = 64
        maxEpochs = 2
        
        learningRatesPerSample = 0.00015
        momentumAsTimeConstant = 600
        
        firstMBsToShowResult = 5
        numMBsToShowResult = 235
    }

    reader = {
        readerType = "CNTKTextFormatReader"
        # See ../README.md for details on getting the data (Train-28x28_cntk_text.txt).
        file = "$DataDir$/Train-28x28_cntk_text.txt"
        input = {
            features = { dim = 784 ; format = "dense" }
            labels =   { dim = 10  ; format = "dense" }
        }
    }   
}

# TEST CONFIG
testNetwork = {
    action = "test"
    minibatchSize = 1024    # reduce this if you run out of memory

    reader = {
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/Test-28x28_cntk_text.txt"
        input = {
            features = { dim = 784 ; format = "dense" }
            labels =   { dim = 10  ; format = "dense" }
        }
    }
}

# WRITE CONFIG
writeResults = {
    action = "write"
    minibatchSize = 1
    outputPath = "$outputDir$/output.txt"
    #outputNodeNames = "z"
    
    reader = {
        randomize = False
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/Dummy.txt"
        input = {
            features = { dim = 784 ; format = "dense" }
            labels =   { dim = 10  ; format = "dense" }
        }
    }
}
